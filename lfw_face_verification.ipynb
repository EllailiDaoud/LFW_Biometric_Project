{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Face Recognition Login Demo with Cancelable Biometrics & Fuzzy Commitment\n",
                "## End-to-End System using LFW Dataset\n",
                "\n",
                "This notebook implements a complete face verification system that simulates a login experience.\n",
                "**Key Features:**\n",
                "- **Face Embeddings**: Uses `facenet-pytorch` (InceptionResnetV1) to convert faces to 512-d vectors.\n",
                "- **Cancelable Biometrics**: Implements a seed-based permutation/transformation to protect raw templates.\n",
                "- **Fuzzy Commitment**: Adds an extra layer of security using Error Correcting Codes (Reed-Solomon) to bind a cryptographic key to the biometric data.\n",
                "- **Performance Evaluation**: Calculates FAR, FRR, and EER for both baseline and secured systems.\n",
                "- **Interactive UI**: A Gradio web app running inside the notebook.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cpu\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/dxs/Documents/s5/project_biom/nb/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
                        "  return torch._C._cuda_getDeviceCount() > 0\n"
                    ]
                }
            ],
            "source": [
                "# Robust installation\n",
                "!pip install --upgrade -q pip setuptools wheel\n",
                "!pip install -q gradio reedsolo\n",
                "!pip install -q facenet-pytorch --no-deps torchvision\n",
                "\n",
                "import os\n",
                "import random\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import cv2\n",
                "from PIL import Image\n",
                "from tqdm.notebook import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.metrics import roc_curve, auc\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "\n",
                "import torch\n",
                "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
                "import reedsolo\n",
                "\n",
                "import gradio as gr\n",
                "\n",
                "# Reproducibility\n",
                "SEED = 42\n",
                "def seed_everything(seed=42):\n",
                "    random.seed(seed)\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed(seed)\n",
                "        torch.backends.cudnn.deterministic = True\n",
                "\n",
                "seed_everything(SEED)\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset Loading\n",
                "Scanning the LFW dataset folder to build an index of identities and their images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 13233 images for 5749 identities.\n",
                        "People with >= 2 images: 1680\n"
                    ]
                }
            ],
            "source": [
                "LFW_DIR = './lfw_funneled'\n",
                "\n",
                "if not os.path.exists(LFW_DIR):\n",
                "    if os.path.exists('archive.zip'):\n",
                "        print(\"Unzipping dataset...\")\n",
                "        !unzip -q archive.zip\n",
                "    else:\n",
                "        print(\"Warning: LFW dataset not found.\")\n",
                "\n",
                "def scan_dataset(root_dir):\n",
                "    paths = []\n",
                "    identities = []\n",
                "    if not os.path.exists(root_dir):\n",
                "        return pd.DataFrame(columns=['name', 'path'])\n",
                "    for person_name in sorted(os.listdir(root_dir)):\n",
                "        person_dir = os.path.join(root_dir, person_name)\n",
                "        if os.path.isdir(person_dir):\n",
                "            images = sorted([f for f in os.listdir(person_dir) if f.lower().endswith(('.jpg', '.png'))])\n",
                "            for img in images:\n",
                "                paths.append(os.path.join(person_dir, img))\n",
                "                identities.append(person_name)\n",
                "    return pd.DataFrame({'name': identities, 'path': paths})\n",
                "\n",
                "df_lfw = scan_dataset(LFW_DIR)\n",
                "print(f\"Found {len(df_lfw)} images for {df_lfw['name'].nunique()} identities.\")\n",
                "\n",
                "def get_images_of_person(name, max_imgs=5):\n",
                "    subset = df_lfw[df_lfw['name'] == name]\n",
                "    return subset['path'].head(max_imgs).tolist()\n",
                "\n",
                "# People with enough images for enrolling + testing\n",
                "people_counts = df_lfw['name'].value_counts()\n",
                "enrolled_candidates = people_counts[people_counts >= 2].index.tolist()\n",
                "print(f\"People with >= 2 images: {len(enrolled_candidates)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Face Embedding Model\n",
                "Loading FaceNet (InceptionResnetV1)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model loaded.\n"
                    ]
                }
            ],
            "source": [
                "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
                "mtcnn = MTCNN(image_size=160, margin=0, keep_all=False, device=device)\n",
                "\n",
                "def get_embedding(img_path_or_array):\n",
                "    if isinstance(img_path_or_array, str):\n",
                "        try:\n",
                "            img = Image.open(img_path_or_array)\n",
                "        except Exception:\n",
                "            return None\n",
                "    elif isinstance(img_path_or_array, np.ndarray):\n",
                "        img = Image.fromarray(cv2.cvtColor(img_path_or_array, cv2.COLOR_BGR2RGB))\n",
                "    else:\n",
                "        img = img_path_or_array\n",
                "    \n",
                "    try:\n",
                "        img_cropped = mtcnn(img)\n",
                "    except Exception:\n",
                "        return None\n",
                "        \n",
                "    if img_cropped is not None:\n",
                "        img_tensor = img_cropped.unsqueeze(0).to(device)\n",
                "        with torch.no_grad():\n",
                "            embedding = resnet(img_tensor).cpu().numpy().flatten()\n",
                "        return embedding\n",
                "    return None\n",
                "\n",
                "print(\"Model loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Baseline Performance Evaluation\n",
                "Simulating the LFW verification protocol to establish a baseline (FAR at different thresholds)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading pairs from pairsDevTest.txt\n",
                        "Evaluated on 1000 pairs.\n"
                    ]
                }
            ],
            "source": [
                "# Load Pairs\n",
                "PAIRS_PATH = 'pairsDevTest.txt'\n",
                "if not os.path.exists(PAIRS_PATH):\n",
                "    # Fallback to creating random pairs from existing data if file missing\n",
                "    print(\"Pairs file not found. Generatig random pairs for eval...\")\n",
                "    def generate_pairs(df, num_pairs=500):\n",
                "        pairs = []\n",
                "        # Genuine\n",
                "        multi_img_people = df['name'].value_counts()[df['name'].value_counts() >= 2].index\n",
                "        for _ in range(num_pairs // 2):\n",
                "            p = np.random.choice(multi_img_people)\n",
                "            imgs = df[df['name'] == p]['path'].sample(2).tolist()\n",
                "            pairs.append({'p1': imgs[0], 'p2': imgs[1], 'label': 1})\n",
                "        # Impostor\n",
                "        for _ in range(num_pairs // 2):\n",
                "            p1, p2 = np.random.choice(df['name'].unique(), 2, replace=False)\n",
                "            img1 = df[df['name'] == p1]['path'].sample(1).iloc[0]\n",
                "            img2 = df[df['name'] == p2]['path'].sample(1).iloc[0]\n",
                "            pairs.append({'p1': img1, 'p2': img2, 'label': 0})\n",
                "        return pd.DataFrame(pairs)\n",
                "    df_pairs = generate_pairs(df_lfw)\n",
                "else:\n",
                "    print(f\"Loading pairs from {PAIRS_PATH}\")\n",
                "    pairs_list = []\n",
                "    with open(PAIRS_PATH, 'r') as f:\n",
                "        lines = f.readlines()[1:] # Skip header\n",
                "        for line in lines:\n",
                "            parts = line.strip().split()\n",
                "            if len(parts) == 3:\n",
                "                name = parts[0]\n",
                "                # Construct paths assuming lfw structure\n",
                "                p1 = os.path.join(LFW_DIR, name, f\"{name}_{int(parts[1]):04d}.jpg\")\n",
                "                p2 = os.path.join(LFW_DIR, name, f\"{name}_{int(parts[2]):04d}.jpg\")\n",
                "                pairs_list.append({'p1': p1, 'p2': p2, 'label': 1})\n",
                "            elif len(parts) == 4:\n",
                "                name1, idx1, name2, idx2 = parts\n",
                "                p1 = os.path.join(LFW_DIR, name1, f\"{name1}_{int(idx1):04d}.jpg\")\n",
                "                p2 = os.path.join(LFW_DIR, name2, f\"{name2}_{int(idx2):04d}.jpg\")\n",
                "                pairs_list.append({'p1': p1, 'p2': p2, 'label': 0})\n",
                "    df_pairs = pd.DataFrame(pairs_list)\n",
                "\n",
                "print(f\"Evaluated on {len(df_pairs)} pairs.\")\n",
                "\n",
                "def evaluate_baseline(df_pairs):\n",
                "    scores = []\n",
                "    labels = []\n",
                "    \n",
                "    # print(\"Computing embeddings for evaluation pairs...\")\n",
                "    # Cache embeddings to avoid re-computing\n",
                "    cache = {}\n",
                "    \n",
                "    for idx, row in tqdm(df_pairs.iterrows(), total=len(df_pairs)):\n",
                "        p1, p2, label = row['p1'], row['p2'], row['label']\n",
                "        \n",
                "        if p1 not in cache: cache[p1] = get_embedding(p1)\n",
                "        if p2 not in cache: cache[p2] = get_embedding(p2)\n",
                "        \n",
                "        emb1 = cache[p1]\n",
                "        emb2 = cache[p2]\n",
                "        \n",
                "        if emb1 is not None and emb2 is not None:\n",
                "            score = cosine_similarity([emb1], [emb2])[0][0]\n",
                "            scores.append(score)\n",
                "            labels.append(label)\n",
                "            \n",
                "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    \n",
                "    # Calculate EER\n",
                "    fnr = 1 - tpr\n",
                "    eer_threshold = thresholds[np.nanargmin(np.absolute((fnr - fpr)))]\n",
                "    EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
                "    \n",
                "    plt.figure()\n",
                "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
                "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
                "    plt.xlabel('False Positive Rate')\n",
                "    plt.ylabel('True Positive Rate')\n",
                "    plt.title('Baseline ROC')\n",
                "    plt.legend(loc=\"lower right\")\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"Baseline EER: {EER:.4f} at Threshold: {eer_threshold:.4f}\")\n",
                "    return eer_threshold\n",
                "\n",
                "# Run Baseline Eval (Uncomment to run automatically separately)\n",
                "# baseline_threshold = evaluate_baseline(df_pairs.sample(200)) # Sample for speed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Security Layer 1: Cancelable Biometrics (BioHashing)\n",
                "Transforming embeddings using a seed-based permutation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "def protect_template_biohash(embedding, seed):\n",
                "    if embedding is None: return None\n",
                "    np.random.seed(int(seed))\n",
                "    perm = np.random.permutation(len(embedding))\n",
                "    return embedding[perm]\n",
                "\n",
                "def verify_biohash(probe, ref, seed, threshold):\n",
                "    if probe is None or ref is None: return 0.0, False\n",
                "    prot_probe = protect_template_biohash(probe, seed)\n",
                "    score = cosine_similarity([prot_probe], [ref])[0][0]\n",
                "    return score, score >= threshold"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Security Layer 2: Fuzzy Commitment Scheme\n",
                "Using Error Correcting Codes (Reed-Solomon) to bind a key to the face data.\n",
                "\n",
                "**Steps:**\n",
                "1. **Binarization**: Convert float embedding to binary string (Feature Vector $F$).\n",
                "2. **Enrollment**:\n",
                "   - Generate random Key $K$.\n",
                "   - ECC Encode $K$ to get Codeword $C$.\n",
                "   - Calculate Helper Data $H = F \\oplus C$ (XOR).\n",
                "   - Store $Hash(K)$ and $H$.\n",
                "3. **Authentication**:\n",
                "   - Compute Feature $F'$ from probe.\n",
                "   - Retrieve $H$.\n",
                "   - Calculate Candidate Codeword $C' = F' \\oplus H = F' \\oplus (F \\oplus C) = (F' \\oplus F) \\oplus C = E \\oplus C$ (where $E$ is error).\n",
                "   - ECC Decode $C'$ to retrieve $K'$.\n",
                "   - Verify $Hash(K') == Hash(K)$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Binarization of Embedding\n",
                "def binarize_embedding(embedding):\n",
                "    # Simple sign-based binarization relative to median/mean\n",
                "    if embedding is None: return None\n",
                "    threshold = np.median(embedding)\n",
                "    binary = (embedding > threshold).astype(int)\n",
                "    return binary\n",
                "\n",
                "# Fuzzy Commitment Class\n",
                "class FuzzyCommitment:\n",
                "    def __init__(self, key_len=16, error_correction_bytes=16):\n",
                "        self.rsc = reedsolo.RSCodec(error_correction_bytes)\n",
                "        self.key_len = key_len\n",
                "        \n",
                "    def enroll(self, feature_vector):\n",
                "        # 1. Generate Random Key\n",
                "        key = os.urandom(self.key_len)\n",
                "        \n",
                "        # 2. Encode Key to Codeword\n",
                "        # RSCodec encodes bytes. We need a codeword length <= feature length\n",
                "        # Feature vector (512 bits) -> can hide ~64 bytes of data max if 1-to-1\n",
                "        # ReedSolo adds EC bytes. Total len = key_len + ec_bytes\n",
                "        codeword = self.rsc.encode(key)\n",
                "        codeword_bits = np.unpackbits(np.frombuffer(codeword, dtype=np.uint8))\n",
                "        \n",
                "        # Pad or Truncate feature to match codeword length\n",
                "        # FaceNet 512 dimensions -> 512 bits.\n",
                "        # If codeword is smaller, we replicate or pad. If larger, we need more features.\n",
                "        # For Demo: using 512 features.\n",
                "        if len(feature_vector) < len(codeword_bits):\n",
                "            # print(f\"Warning: Feature vector too short ({len(feature_vector)}) for codeword ({len(codeword_bits)})\")\n",
                "            return None, None\n",
                "            \n",
                "        # Align lengths\n",
                "        feat_bits = feature_vector[:len(codeword_bits)]\n",
                "        \n",
                "        # 3. Helper Data (XOR)\n",
                "        helper = np.bitwise_xor(feat_bits, codeword_bits)\n",
                "        \n",
                "        key_hash = hash(key) # Simple hash for demo\n",
                "        return key_hash, helper\n",
                "        \n",
                "    def authenticate(self, helper, probe_vector, stored_hash):\n",
                "        # 1. Align Probe\n",
                "        codeword_len = len(helper)\n",
                "        if len(probe_vector) < codeword_len:\n",
                "            return False\n",
                "        probe_bits = probe_vector[:codeword_len]\n",
                "        \n",
                "        # 2. XOR to recover noisy codeword\n",
                "        noisy_codeword_bits = np.bitwise_xor(probe_bits, helper)\n",
                "        noisy_codeword_bytes = np.packbits(noisy_codeword_bits).tobytes()\n",
                "        \n",
                "        # 3. Decode\n",
                "        try:\n",
                "            decoded_key, _, _ = self.rsc.decode(noisy_codeword_bytes)\n",
                "            # 4. Verify Hash\n",
                "            if hash(decoded_key) == stored_hash:\n",
                "                return True\n",
                "        except reedsolo.ReedSolomonError:\n",
                "            pass\n",
                "            \n",
                "        return False\n",
                "\n",
                "# Initialize global FC scheme\n",
                "fc_system = FuzzyCommitment(key_len=16, error_correction_bytes=16)\n",
                "# Note: 16 bytes key + 16 bytes EC = 32 bytes = 256 bits. Well within 512-bit embedding."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Interactive System (Updated)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "* Running on local URL:  http://127.0.0.1:7860\n",
                        "* Running on public URL: https://d18faea5a70f459bb2.gradio.live\n",
                        "\n",
                        "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div><iframe src=\"https://d18faea5a70f459bb2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": []
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Global State Update\n",
                "DB = {} \n",
                "SYSTEM_SEED = 12345\n",
                "LOGS = []\n",
                "\n",
                "def enroll(name, img, modes):\n",
                "    raw = get_embedding(img)\n",
                "    if raw is None: return \"Face fail\", {}, gr.update()\n",
                "    if not modes: return \"Please select a security mode\", {}, gr.update()\n",
                "    \n",
                "    record = {'img': img}\n",
                "    info = {}\n",
                "\n",
                "    if \"BioHash\" in modes:\n",
                "        tmpl = protect_template_biohash(raw, SYSTEM_SEED)\n",
                "        record['biohash'] = tmpl\n",
                "        info['BioHash'] = str(tmpl.shape)\n",
                "    \n",
                "    if \"FuzzyCommitment\" in modes:\n",
                "        binary = binarize_embedding(raw)\n",
                "        key_hash, helper = fc_system.enroll(binary)\n",
                "        if key_hash is None: return \"Enroll fail (dim error)\", {}, gr.update()\n",
                "        record['fc'] = {'hash': key_hash, 'helper': helper}\n",
                "        info['FC_Helper'] = len(helper)\n",
                "        \n",
                "    DB[name] = record\n",
                "    return f\"Enrolled {name} with {modes}\", info, gr.update(choices=list(DB.keys()))\n",
                "\n",
                "def authenticate(name, img, threshold):\n",
                "    if not name: return \"Please select a user\", 0.0, False\n",
                "    if name not in DB: return \"User not found\", 0.0, False\n",
                "    \n",
                "    record = DB[name]\n",
                "    raw = get_embedding(img)\n",
                "    if raw is None: return \"Face fail\", 0.0, False\n",
                "    \n",
                "    results = []\n",
                "    decisions = []\n",
                "    \n",
                "    if 'biohash' in record:\n",
                "        score, decision = verify_biohash(raw, record['biohash'], SYSTEM_SEED, threshold)\n",
                "        results.append(f\"BioHash: {'Match' if decision else 'Fail'} ({score:.3f})\")\n",
                "        decisions.append(decision)\n",
                "        \n",
                "    if 'fc' in record:\n",
                "        binary = binarize_embedding(raw)\n",
                "        fc_rec = record['fc']\n",
                "        decision = fc_system.authenticate(fc_rec['helper'], binary, fc_rec['hash'])\n",
                "        results.append(f\"FC: {'Success' if decision else 'Fail'}\")\n",
                "        decisions.append(decision)\n",
                "    \n",
                "    final_str = \" | \".join(results)\n",
                "    final_bool = any(decisions) if decisions else False\n",
                "    \n",
                "    return final_str, 0.0, final_bool\n",
                "\n",
                "# Setup Gradio\n",
                "with gr.Blocks() as app:\n",
                "    gr.Markdown(\"# Secure Face Login (BioHash & Fuzzy Commitment)\")\n",
                "    \n",
                "    with gr.Tab(\"Enroll\"):\n",
                "        gr.Markdown(\"Select a person from the dataset or upload your own image.\")\n",
                "        with gr.Row():\n",
                "            with gr.Column():\n",
                "                # Limit dropdown to top 200 for performance\n",
                "                top_candidates = enrolled_candidates[:200]\n",
                "                en_dropdown = gr.Dropdown(choices=top_candidates, label=\"Select Person from LFW\", filterable=True)\n",
                "                en_img = gr.Image(type=\"filepath\", label=\"Face Image\")\n",
                "                if not top_candidates: print(\"Warning: Candidate list is empty!\")\n",
                "            with gr.Column():\n",
                "                en_name = gr.Textbox(label=\"User ID (Name)\")\n",
                "                en_mode = gr.CheckboxGroup([\"BioHash\", \"FuzzyCommitment\"], label=\"Security Modes\", value=[\"BioHash\"])\n",
                "                en_btn = gr.Button(\"Enroll\", variant=\"primary\")\n",
                "        \n",
                "        en_out = gr.JSON(label=\"Enrollment Info\")\n",
                "        en_res = gr.Textbox(label=\"Status\")\n",
                "        \n",
                "        # Dropdown logic\n",
                "        def on_select_person(name):\n",
                "            if not name: return None, \"\"\n",
                "            imgs = get_images_of_person(name)\n",
                "            if not imgs: return None, name\n",
                "            return imgs[0], name\n",
                "            \n",
                "        en_dropdown.change(on_select_person, en_dropdown, [en_img, en_name])\n",
                "        en_btn.click(enroll, [en_name, en_img, en_mode], [en_res, en_out, \n",
                "                                                          gr.Dropdown(label=\"Claimed Identity (Enrolled Users)\", choices=[], interactive=True)]) \n",
                "        # Note: We need a handle to the auth dropdown output in the enroll click, \n",
                "        # but since 'au_name' is defined in the next tab scope block, we can't reference it easily \n",
                "        # UNLESS we define components first. Let's restructure slightly to ensure Variable visibility.\n",
                "\n",
                "    with gr.Tab(\"Authenticate\"):\n",
                "        with gr.Row():\n",
                "            # Dropdown for enrolled users (starts empty)\n",
                "            au_name = gr.Dropdown(label=\"Claimed Identity (Enrolled Users)\", choices=[], interactive=True)\n",
                "            au_img = gr.Image(type=\"filepath\")\n",
                "            au_thresh = gr.Slider(0.0, 1.0, 0.6, label=\"BioHash Threshold\")\n",
                "            au_btn = gr.Button(\"Login\", variant=\"primary\")\n",
                "        au_res = gr.Textbox(label=\"Result\")\n",
                "        au_btn.click(authenticate, [au_name, au_img, au_thresh], [au_res, gr.Number(label=\"Score\", visible=False), gr.State()])\n",
                "\n",
                "    # Link Enroll button to Auth Dropdown update (Need to act on the au_name object defined above)\n",
                "    en_btn.click(enroll, [en_name, en_img, en_mode], [en_res, en_out, au_name])\n",
                "\n",
                "    with gr.Tab(\"Evaluation\"):\n",
                "        gr.Markdown(\"## Comparative Performance Evaluation\")\n",
                "        ev_modes = gr.CheckboxGroup([\"Baseline\", \"BioHash\", \"FuzzyCommitment\"], label=\"Select Methods to Evaluate\", value=[\"Baseline\"])\n",
                "        ev_btn = gr.Button(\"Run Comparative Evaluation\")\n",
                "        ev_out_text = gr.Markdown(label=\"Results Summary\")\n",
                "        ev_plot = gr.Plot(label=\"ROC Curves\")\n",
                "        \n",
                "        def run_comparative_eval(modes):\n",
                "            # Subset for speed\n",
                "            subset = df_pairs.sample(min(200, len(df_pairs)))\n",
                "            results_text = \"### Evaluation Results\\n\"\n",
                "            plt.figure(figsize=(8, 6))\n",
                "            \n",
                "            # 1. Baseline\n",
                "            if \"Baseline\" in modes:\n",
                "                # print(\"Running Baseline...\")\n",
                "                scores, labels = [], []\n",
                "                for _, row in subset.iterrows():\n",
                "                    e1, e2 = get_embedding(row['p1']), get_embedding(row['p2'])\n",
                "                    if e1 is not None and e2 is not None:\n",
                "                        scores.append(cosine_similarity([e1], [e2])[0][0])\n",
                "                        labels.append(row['label'])\n",
                "                if scores:\n",
                "                    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
                "                    roc_auc = auc(fpr, tpr)\n",
                "                    # EER\n",
                "                    fnr = 1 - tpr\n",
                "                    eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
                "                    plt.plot(fpr, tpr, label=f'Baseline (AUC={roc_auc:.2f}, EER={eer:.2f})')\n",
                "                    results_text += f\"- **Baseline**: EER = {eer:.4f}, AUC = {roc_auc:.4f}\\n\"\n",
                "\n",
                "            # 2. BioHash\n",
                "            if \"BioHash\" in modes:\n",
                "                # print(\"Running BioHash...\")\n",
                "                scores, labels = [], []\n",
                "                for _, row in subset.iterrows():\n",
                "                    e1, e2 = get_embedding(row['p1']), get_embedding(row['p2'])\n",
                "                    if e1 is not None and e2 is not None:\n",
                "                        # Permute BOTH\n",
                "                        p1 = protect_template_biohash(e1, SYSTEM_SEED)\n",
                "                        p2 = protect_template_biohash(e2, SYSTEM_SEED)\n",
                "                        scores.append(cosine_similarity([p1], [p2])[0][0])\n",
                "                        labels.append(row['label'])\n",
                "                if scores:\n",
                "                    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
                "                    roc_auc = auc(fpr, tpr)\n",
                "                    fnr = 1 - tpr\n",
                "                    eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
                "                    plt.plot(fpr, tpr, linestyle='--', label=f'BioHash (AUC={roc_auc:.2f}, EER={eer:.2f})')\n",
                "                    results_text += f\"- **BioHash**: EER = {eer:.4f}, AUC = {roc_auc:.4f}\\n\"\n",
                "\n",
                "            # 3. Fuzzy Commitment\n",
                "            if \"FuzzyCommitment\" in modes:\n",
                "                # print(\"Running FC...\")\n",
                "                correct_gen, total_gen = 0, 0\n",
                "                correct_imp, total_imp = 0, 0\n",
                "                for _, row in subset.iterrows():\n",
                "                    e1, e2 = get_embedding(row['p1']), get_embedding(row['p2'])\n",
                "                    if e1 is not None and e2 is not None:\n",
                "                        bin1 = binarize_embedding(e1)\n",
                "                        key, helper = fc_system.enroll(bin1)\n",
                "                        if key is None: continue\n",
                "                        \n",
                "                        bin2 = binarize_embedding(e2)\n",
                "                        success = fc_system.authenticate(helper, bin2, key)\n",
                "                        \n",
                "                        if row['label'] == 1:\n",
                "                            total_gen += 1\n",
                "                            if success: correct_gen += 1\n",
                "                        else:\n",
                "                            total_imp += 1\n",
                "                            if not success: correct_imp += 1\n",
                "                \n",
                "                gar = correct_gen / total_gen if total_gen > 0 else 0\n",
                "                far = (total_imp - correct_imp) / total_imp if total_imp > 0 else 0\n",
                "                results_text += f\"- **Fuzzy Commitment**: GAR = {gar:.2%}, FAR = {far:.2%}\\n\"\n",
                "\n",
                "            plt.plot([0, 1], [0, 1], 'k--')\n",
                "            plt.xlabel('False Positive Rate')\n",
                "            plt.ylabel('True Positive Rate')\n",
                "            plt.title('ROC Curve Comparison')\n",
                "            plt.legend()\n",
                "            return results_text, plt.gcf()\n",
                "\n",
                "        ev_btn.click(run_comparative_eval, ev_modes, [ev_out_text, ev_plot])\n",
                "\n",
                "app.launch(share=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
